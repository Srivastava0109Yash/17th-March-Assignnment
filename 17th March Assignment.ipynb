{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd0feb7",
   "metadata": {},
   "source": [
    "### Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a72635",
   "metadata": {},
   "source": [
    "- Missing values in a dataset refer to the absence of data in one or more variables for certain observations. It can happen due to a variety of reasons, such as data entry errors, measurement issues, or incomplete surveys.\n",
    "\n",
    "- It is essential to handle missing values because they can introduce bias and inaccuracies in statistical analyses and machine learning models. Missing values can reduce the sample size, leading to a loss of statistical power and efficiency, and distort the estimation of parameters and relationships between variables. Moreover, some algorithms cannot handle missing values, and their use may result in errors or invalid results.\n",
    "\n",
    "__Some algorithms that are not affected by missing values are:__\n",
    "\n",
    "- __Decision Trees:__ Decision trees can handle missing values by treating missing data as a separate category and splitting the data accordingly.\n",
    "\n",
    "- __Random Forest:__ Random Forest is an ensemble method that uses multiple decision trees. It can handle missing values by imputing the missing values before training each tree.\n",
    "\n",
    "- __K-Nearest Neighbors (KNN):__ KNN imputes missing values by taking the average of the nearest neighbors.\n",
    "\n",
    "- __Support Vector Machines (SVM):__ SVM can handle missing values by ignoring the missing values during training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f3b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb01ae16",
   "metadata": {},
   "source": [
    "### Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb0bc1b",
   "metadata": {},
   "source": [
    "There are several techniques that can be used to handle missing data. Here are some of the most commonly used techniques along with an example in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274b5a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    'A':[1,2,3,4,5,6,7,8,9,np.nan],\n",
    "    'B':[2,3,4,5,6,1,2,3,4,np.nan]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a73fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0  1.0  2.0\n",
       "1  2.0  3.0\n",
       "2  3.0  4.0\n",
       "3  4.0  5.0\n",
       "4  5.0  6.0\n",
       "5  6.0  1.0\n",
       "6  7.0  2.0\n",
       "7  8.0  3.0\n",
       "8  9.0  4.0\n",
       "9  NaN  NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492be6e1",
   "metadata": {},
   "source": [
    "- __Deletion:__ In this technique, the observations or variables with missing data are removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "229520a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0  1.0  2.0\n",
       "1  2.0  3.0\n",
       "2  3.0  4.0\n",
       "3  4.0  5.0\n",
       "4  5.0  6.0\n",
       "5  6.0  1.0\n",
       "6  7.0  2.0\n",
       "7  8.0  3.0\n",
       "8  9.0  4.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with missing data\n",
    "df_dropna = df.dropna()\n",
    "df_dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f07f81",
   "metadata": {},
   "source": [
    "- __Imputation:__ In this technique, the missing data is filled in using a statistical method(mean,median,mode) or a value that is derived from the other observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72e694fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A         B\n",
       "0  1.0  2.000000\n",
       "1  2.0  3.000000\n",
       "2  3.0  4.000000\n",
       "3  4.0  5.000000\n",
       "4  5.0  6.000000\n",
       "5  6.0  1.000000\n",
       "6  7.0  2.000000\n",
       "7  8.0  3.000000\n",
       "8  9.0  4.000000\n",
       "9  5.0  3.333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed=df.fillna(df.mean())\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080aceec",
   "metadata": {},
   "source": [
    "__Interpolation:__ In this technique, the missing data is estimated using the values of neighboring observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03818a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0  1.0  2.0\n",
       "1  2.0  3.0\n",
       "2  3.0  4.0\n",
       "3  4.0  5.0\n",
       "4  5.0  6.0\n",
       "5  6.0  1.0\n",
       "6  7.0  2.0\n",
       "7  8.0  3.0\n",
       "8  9.0  4.0\n",
       "9  9.0  4.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interpolated=df.interpolate()\n",
    "df_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa6557b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "648b6bf6",
   "metadata": {},
   "source": [
    "### Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41faa647",
   "metadata": {},
   "source": [
    "__Imbalanced data__ is a type of dataset where the distribution of classes is not equal. In other words, some classes have significantly more instances than others. <br>For example, in a binary classification problem where the positive class represents a rare event, the dataset may have only a small proportion of positive instances compared to negative instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea30ac",
   "metadata": {},
   "source": [
    "__if imbalanced data is not handled__\n",
    "\n",
    "- If imbalanced data is not handled properly, it can lead to biased models that are not able to accurately predict the minority class. In such cases, the model may prioritize the majority class and classify all instances as belonging to that class, resulting in poor performance on the minority class.\n",
    "\n",
    "- Moreover, if the model is not able to distinguish between the minority class and the majority class, it may lead to missed opportunities or serious consequences, especially in applications such as fraud detection, disease diagnosis, and risk assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c3bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7057dc3",
   "metadata": {},
   "source": [
    "### Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9336c01",
   "metadata": {},
   "source": [
    "- Up-sampling involves increasing the number of instances in the minority class to balance the distribution between the classes. This can be done by randomly duplicating instances in the minority class or by generating new synthetic instances that are similar to the existing minority class instances. The goal is to increase the representation of the minority class in the dataset, making it more likely for the model to correctly identify instances belonging to this class.\n",
    "\n",
    "- Down-sampling involves decreasing the number of instances in the majority class to balance the distribution between the classes. This can be done by randomly removing instances from the majority class or by selecting a representative subset of the majority class instances. The goal is to reduce the dominance of the majority class in the dataset, making it easier for the model to identify instances belonging to the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ed348",
   "metadata": {},
   "source": [
    "__Example:__\n",
    "    \n",
    "- An example when up-sampling and down-sampling are required is in a credit card fraud detection system. Suppose the dataset contains information about credit card transactions, where only a small percentage of transactions are fraudulent. The dataset is imbalanced, with the majority class being the non-fraudulent transactions. In this case, up-sampling the minority class by generating synthetic instances or duplicating instances can be used to balance the dataset and improve the model's ability to detect fraudulent transactions. Alternatively, down-sampling the majority class by selecting a representative subset of non-fraudulent transactions can also be used to balance the dataset and improve the model's ability to detect fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579a584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3120b7ae",
   "metadata": {},
   "source": [
    "### Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3d2ca",
   "metadata": {},
   "source": [
    "__Data Augmentation__ is a technique used to artificially increase the size of a dataset by creating new instances from the existing ones. The goal is to improve the model's ability to generalize to new data and reduce the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2581c3d1",
   "metadata": {},
   "source": [
    "__SMOTE__<br>\n",
    "- One popular data augmentation technique for handling imbalanced data is __Synthetic Minority Over-sampling Technique (SMOTE)__. SMOTE works by creating synthetic instances of the minority class by interpolating between the existing minority class instances. \n",
    "\n",
    "- it selects a random minority class instance and its k nearest minority class neighbors, and then generates a new instance by randomly selecting features from the original instance and its neighbors and computing their average.\n",
    "\n",
    "- SMOTE is a powerful technique that can effectively balance imbalanced datasets and improve the model's ability to correctly identify instances belonging to the minority class. However, it should be used with caution as it can also introduce noise and overfitting if the synthetic instances are not representative of the underlying data distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cee42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ec8e093",
   "metadata": {},
   "source": [
    "### Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce305ac",
   "metadata": {},
   "source": [
    "__Outliers__ are observations in a dataset that deviate significantly from the rest of the data points. Outliers can be caused by various factors such as measurement errors, data entry errors, or extreme values in the underlying population.\n",
    "\n",
    "__Handling outliers__ is important because they can have a significant impact on statistical analysis and machine learning models. Outliers can distort the data distribution, affect the mean and standard deviation of the data, and bias the results of statistical tests. In machine learning, outliers can lead to overfitting of the model, where the model learns to fit the noise in the data rather than the underlying patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c2b459",
   "metadata": {},
   "source": [
    "Therefore, handling outliers is essential to ensure accurate and reliable analysis and modeling. There are various techniques to handle outliers, including:\n",
    "\n",
    "- Removing outliers: This involves removing the outlier values from the dataset. However, this approach can lead to loss of information and may not be suitable if the outliers represent valid data points.\n",
    "\n",
    "- Transformations: This involves transforming the data using mathematical functions such as logarithmic or power transformations. This can reduce the impact of outliers and make the data distribution more normal.\n",
    "\n",
    "- Robust methods: This involves using statistical methods that are less sensitive to outliers, such as the median instead of the mean or non-parametric methods such as the median absolute deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e42e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9987d9d7",
   "metadata": {},
   "source": [
    "### Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa1a89",
   "metadata": {},
   "source": [
    "There are various techniques that can be used to handle missing data in customer data analysis. Some of these techniques are:\n",
    "\n",
    "__Deleting missing values__: This involves removing the rows or columns that contain missing values. However, this approach can lead to loss of information and may not be suitable if the missing values represent valid data points.\n",
    "\n",
    "__Imputation__: This involves filling in the missing values with estimated values based on the available data. There are various imputation techniques, including mean imputation, median imputation, mode imputation, and regression imputation. For example, if there is a missing value for a customer's age, we can impute the mean or median age of the available data for the missing value.\n",
    "\n",
    "__Model-based imputation__: This involves using machine learning models to estimate the missing values based on the available data. For example, we can use a decision tree or random forest model to predict the missing values based on other features in the dataset.\n",
    "\n",
    "__Multiple imputation__: This involves generating multiple imputed datasets and analyzing them separately to obtain more accurate estimates. This approach is particularly useful when there are many missing values in the data.\n",
    "\n",
    "__Interpolation__: This involves using mathematical methods to estimate the missing values based on the available data. For example, we can use linear interpolation to estimate missing values in a time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59388b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924b43c0",
   "metadata": {},
   "source": [
    "### Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936bcdf1",
   "metadata": {},
   "source": [
    "When dealing with missing data, it is important to determine whether the missing data is missing at random (MAR) or missing not at random (MNAR). Missing at random means that the missingness is unrelated to the unobserved value and can be predicted by the observed data, while missing not at random means that the missingness is related to the unobserved value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8650f8",
   "metadata": {},
   "source": [
    "__Here are some strategies that can be used to determine if the missing data is missing at random or not:__\n",
    "\n",
    "- Visualization: One way to determine if there is a pattern to the missing data is to visualize the missingness using a missingness plot. This plot shows the missingness pattern of each variable in the dataset. If the missingness is random, then the missingness plot will show a random pattern of missing data. If there is a pattern to the missing data, then the missingness plot will show a non-random pattern.\n",
    "\n",
    "\n",
    "- Statistical tests: There are various statistical tests that can be used to determine if the missing data is missing at random or not. For example, the Little's MCAR test can be used to test if the missing data is missing completely at random (MCAR), while the missingness pattern test can be used to test if the missing data is missing at random or not.\n",
    "\n",
    "\n",
    "- Imputation: Imputation methods such as mean imputation, median imputation, or regression imputation can be used to estimate the missing data. If the imputed values are similar to the observed values, then the missing data is likely missing at random.\n",
    "\n",
    "\n",
    "- Machine learning models: Machine learning models such as decision trees, random forests, or logistic regression can be used to predict the missing values. If the model performance is similar for the observed and missing data, then the missing data is likely missing at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb088d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11b1e417",
   "metadata": {},
   "source": [
    "### Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2928f55d",
   "metadata": {},
   "source": [
    "Dealing with imbalanced datasets is a common challenge in machine learning, particularly in medical diagnosis projects. Here are some strategies that can be used to evaluate the performance of a machine learning model on an imbalanced dataset:\n",
    "\n",
    "\n",
    "- Confusion matrix: The confusion matrix provides a summary of the model's performance on the imbalanced dataset. It includes metrics such as accuracy, precision, recall, and F1 score, which can be used to evaluate the model's performance on both the majority and minority classes.\n",
    "\n",
    "- Resampling techniques: Resampling techniques such as oversampling and undersampling can be used to balance the dataset. Oversampling involves creating synthetic samples for the minority class, while undersampling involves removing samples from the majority class. These techniques can help the model to better learn the minority class and improve its performance.\n",
    "\n",
    "- Ensemble methods: Ensemble methods such as bagging, boosting, or stacking can be used to combine multiple models to improve the overall performance on the imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c9410b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "267e6a92",
   "metadata": {},
   "source": [
    "### Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf39e62",
   "metadata": {},
   "source": [
    "When working with an unbalanced dataset, where the majority class dominates the dataset, it can be challenging to accurately estimate customer satisfaction. Here are some methods that can be used to balance the dataset and down-sample the majority class:\n",
    "\n",
    "- Undersampling: Undersampling involves randomly removing samples from the majority class until the dataset is balanced. For example, if the majority class represents 80% of the dataset, a random sample of 40% of the majority class could be selected and combined with the minority class to create a balanced dataset.\n",
    "\n",
    "- Oversampling: Oversampling involves creating synthetic samples for the minority class until the dataset is balanced. For example, synthetic samples could be generated using methods such as SMOTE, ADASYN or ROSE.\n",
    "\n",
    "- Ensemble methods: Ensemble methods such as bagging or boosting can be used to combine multiple models trained on balanced subsets of the data. These methods can help to reduce the impact of the majority class on the overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd89d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c29fccf",
   "metadata": {},
   "source": [
    "### Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3687c5ef",
   "metadata": {},
   "source": [
    "When working with a dataset that has a low percentage of occurrences, it can be challenging to accurately estimate the occurrence of a rare event. Here are some methods that can be used to balance the dataset and up-sample the minority class:\n",
    "\n",
    "- Oversampling: Oversampling involves creating synthetic samples for the minority class until the dataset is balanced. For example, synthetic samples could be generated using methods such as SMOTE, ADASYN or ROSE.\n",
    "\n",
    "- Anomaly detection: Anomaly detection methods can be used to identify samples that are most likely to belong to the minority class. These samples can be up-sampled to create a balanced dataset.\n",
    "\n",
    "- Ensemble methods: Ensemble methods such as bagging or boosting can be used to combine multiple models trained on balanced subsets of the data. These methods can help to reduce the impact of the majority class on the overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76252a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
